---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# AutoCDAScorer

<!-- badges: start -->

[![codecov](https://codecov.io/gh/joshuandwilliams/AutoCDAScorer/graph/badge.svg?token=DVSFFFKKQ4)](https://codecov.io/gh/joshuandwilliams/AutoCDAScorer) [![R CMD check](https://github.com/joshuandwilliams/AutoCDAScorer/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/joshuandwilliams/AutoCDAScorer/actions/workflows/R-CMD-check.yaml) [![lifecycle](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental) ![R](https://img.shields.io/badge/R-%3E=3.5.0-1e90ff?logo=r) [![tensorflow version](https://img.shields.io/badge/tensorflow-v2.16.2-orange)](https://www.tensorflow.org/)

<!-- badges: end -->

The goal of AutoCDAScorer is to make scoring cell death areas on UV spectra agroinfiltration images faster, more consistent, and less subjective.

AutoCDAScorer uses deep learning models trained on UV spectra agroinfiltration images to automatically predict cell death severity between 0 (no cell death) and 6 (strong cell death).

## Installation

You can install the development version of AutoCDAScorer from [GitHub](https://github.com/) with:

```{r, eval = FALSE}
install.packages("devtools")
devtools::install_github("joshuandwilliams/AutoCDAScorer")
```

The `AutoCDAScorer` package uses TensorFlow. If you already have TensorFlow installed you can use `reticulate::use_condaenv()` to specify the correct environment for R to use. Otherwise you will need to install TensorFlow. You can do this from within R:

``` r
library(AutoCDAScorer)
install_tensorflow()
```

This installation only needs to be done once. After that, TensorFlow will remain installed unless you actively remove it.

## Models available

| Model Name | Description |
|----|----|
| "base_cnn" | CNN model trained on the original (base) dataset. |
| "geom_transformer" | Vision Transformer model trained on a dataset supplemented with geometrically augmented images. |
| "composite_cnn" | CNN model trained on a dataset supplemented with intra-class composite images. |
| "cgan_cnn" | CNN model trained on a dataset of synthetic cGAN images. |

## Usage

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>"
)
```

This is an example workflow to show loading image datasets, checking whether they are appropriate for AutoCDAScorer's models using diagnostic plots, and finally making score predictions.

```{r setup}
library(AutoCDAScorer)
```

```{r mock_cdascorer_csv, include=FALSE}
tmp_cdascorer_csv <- tempfile(fileext = ".csv")
cdascorer_input_path <- system.file("extdata", "example_dataset/cdascorer_example.csv", package = "AutoCDAScorer", mustWork = TRUE)
raw_img_path <- system.file("extdata", "example_dataset/raw_images/image1.tif", package = "AutoCDAScorer")
cdascorer_df <- read.csv(cdascorer_input_path)
cdascorer_df$img <- rep(raw_img_path, nrow(cdascorer_df))
write.csv(cdascorer_df, tmp_cdascorer_csv, row.names = FALSE)
```

## Load CDA image dataset

AutoCDAScorer provides two ways of loading image datasets

Option 1: You can load an existing CDAScorer dataframe, which includes raw images and the coordinates of CDAs to be cropped.

```{r load_cdascorer, fig.width=2, fig.height=2}
cdascorer_output_path <- system.file("extdata", "example_dataset", "cropped_images", package = "AutoCDAScorer", mustWork = TRUE) # Example dataset

your_dataset <- crop_and_load_images(input_path = tmp_cdascorer_csv, output_path = cdascorer_output_path)

show_test_image(your_dataset)
```

Option 2: You can load already-cropped CDA TIFF images from a directory.

```{r load_images, fig.width=2, fig.height=2}
image_directory <- system.file("extdata", "example_dataset", "cropped_images", package = "AutoCDAScorer", mustWork = TRUE)
your_dataset <- load_images(input_path = image_directory)

show_test_image(your_dataset)
```

## Diagnostic plots

AutoCDAScorer provides three types of diagnostic plot to help you gauge whether your images fall within the variation of those seen by the model training. This is important, since models only make accurate predictions on images similar to those they have been trained on.

#### How to interpret these plots?

These diagnostic plots are based on principal components analysis (PCA). The grey cloud represents the image dataset the models were trained on. Your images are more likely to receive accurate score predictions if they fall within this region across all subplots.

```{r positive_diagnostic, fig.height=5, fig.width=6}
rds_path <- system.file("extdata/example_dataset/training_subset/good_dataset.rds", package = "AutoCDAScorer", mustWork = TRUE)
good_dataset <- readRDS(rds_path)

convexhull_plot <- diagnostic_pca(
  "base_cnn",
  good_dataset,
  num_pcs = 5,
  plot_type = "convexhull",
  output_path = NULL
)
convexhull_plot
```

If your images appear outside of the grey cloud (i.e. are different to those used in training), we do not recommend using AutoCDAScorer.

```{r negative_diagnostic, fig.height=5, fig.width=6}
bad_dataset <- good_dataset
bad_dataset$images <- bad_dataset$images[,,,c(3,1,2)] # Mix up the colour channels to make a "bad" set of images

convexhull_plot <- diagnostic_pca(
  "base_cnn",
  bad_dataset,
  num_pcs = 5,
  plot_type = "convexhull",
  output_path = NULL
)
convexhull_plot
```

Sometimes it will be unclear if your images are appropriate for use with AutoCDAScorer. Perhaps some of your images are consistently within the grey cloud whilst others aren't. You should try diagnostic plots using different models to find one whose training images best match your images.

To help you decide, each scatter plot in the top left (coordinates A, B) is paired with an importance plot in the bottom right (coordinates B, A). You should pay more attention to plots with higher importance percentages, since the points on these plots are more reflective of the true similarity between your images and the training images.

```{r real_diagnostic, fig.height=5, fig.width=6}
target_plot <- diagnostic_pca(
  model = "base_cnn",
  your_data = your_dataset,
  num_pcs = 5,
  plot_type = "target",
  num_ellipses = 3
)
target_plot

contour_plot <- diagnostic_pca(
  model = "base_cnn",
  your_data = your_dataset,
  num_pcs = 5,
  plot_type = "density",
  num_bins = 5
)
contour_plot

convexhull_plot <- diagnostic_pca(
  model = "base_cnn",
  your_data = your_dataset,
  num_pcs = 5,
  plot_type = "convexhull"
)
convexhull_plot
```

## Make score predictions

Once you've identified a model whose training images are similar to your own images, you can have that model make predictions on your images.

You can choose the results to be returned as scores between 0-6 (0 = no cell death, 6 = strong cell death) or softmax probabilities (with one column for each score 0-6).

```{r predict}
your_predictions <- predict_score(model = "base_cnn", data = your_dataset, softmax = FALSE)

table(your_predictions)
```
